#
# Copyright (C) 2015 INRA
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#

[global]
# uncomment and set if not in the PATH, should be version = 4.4.3
#makeflow = <path>/cctools-4.4.3/bin/makeflow
# batch system type: local, condor, sge, moab, cluster, wq, hadoop, mpi-queue
batch_system_type = sge
# add these options to all batch submit files
batch_options = 
# add these options to limit the number of jobs sumitted in parallel
limit_submission = 100
# on which socket host should run the web server #NOT AVAILABLE for workflowBS
server_socket_host = 127.0.0.1
# on which socket port should run the web server #NOT AVAILABLE for workflowBS
server_socket_port = 8080
# date format
date_format = %d/%m/%Y

[email]
#NOT AVAILABLE for workflowBS
# if you want an email to be sent at the end of the workflow execution
# set the smtp_server and the from_address values
smtp_server = 
smtp_port = 
from_address = 
from_password = 
# uncomment and set if you want to use these values for all the workflow
# these variables can be overloaded within the workflow implementation by
# using self.set_to_address("address"), self.set_subject("subject"), 
# self.set_message("message") functions
#to_address =
#subject =
#message =

[storage]
# where should be written the log file
log_file = <path>/jflow.log
# Where should the pipelines write results, should be accessible 
# by all cluster nodes
work_directory = <path>/work
# Where should the pipelines write temporary files, should be 
# accessible by all cluster nodes
tmp_directory = <path>/tmp

[softwares]
# uncomment and set if not in the PATH
#fastqc = <path>/FastQC_v0.11.2/fastqc
#samtools = <path>/samtools-1.3/samtools
#trim_galore = <path>/trim_galore_v0.4.0/trim_galore
#bismark = <path>/bismark_v0.15.0/bismark
#bismark_genome_preparation = <path>/bismark_v0.15.0/bismark_genome_preparation
#deduplicate_bismark = <path>/bismark_v0.15.0/deduplicate_bismark
#bowtie2 =  <path>/bowtie2
#R > v3.2
#Rscript=<path>/R-3.2.2/bin/Rscript


[components]
#This section permit to configure memory and CPU options for each component.

#If batch_system_type = local
#Set component option to config programs options used in component
#you can provide option with format "mem=XX[K|M|G] cpu=XX"
FastQC.batch_options = "cpu=8"
BismarkGenomePreparation.batch_options ="mem=2G cpu=8"
Bismark.batch_options = "cpu=6 mem=2G"
RemoveDuplicate.batch_options = "cpu=6 mem=2G"
MethylkitDM.batch_options = "cpu=4"
DssDM.batch_options = "cpu=4"

#If batch_system_type = SGE 
#To avoid to be killed by scheduler set appropriate memory and cpu parameters.
#FastQC.batch_options = "-pe parallel_smp 8"
#BismarkGenomePreparation.batch_options = "-l mem=20G -l h_vmem=20G -q workq"
#Bismark.batch_options = "-pe parallel_smp 12 -l mem=2G -l h_vmem=4G -q workq"
#RemoveDuplicate.batch_options = "-l mem=8G -l h_vmem=10G -pe parallel_smp 12"
#MethylKitDM.batch_options = "-pe parallel_smp 2"
#DssDM.batch_options = "-pe parallel_smp 2"

#If you use another batch_system_type can be update in pipeline 
#code ( see workflows/methylseq/__init__.py ) thoses options
#Default values are :
#	NORMAL_MEM = "2G"
#	LARGE_MEM = "10G"
#	HUGE_MEM = "20G"
#	NORMAL_CPU = 2
#	LARGE_CPU = 8
#	HUGE_CPU = 12
#Default configuration in pipeline is :
#FastQC : LARGE_CPU
#TrimGalore: No options
#Bismark: HUGE_CPU & NORMAL_MEM
#RemoveDuplicate: HUGE_CPU & LARGE_MEM
#MethylationCalling: No options
#MethylKitDM: LARGE_CPU
#DssDM: LARGE_CPU  

# Set workflows group
[workflows]

